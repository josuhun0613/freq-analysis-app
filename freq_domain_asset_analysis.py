"""
Frequency Domain ê¸°ë°˜ ìì‚°êµ°ë³„ í†µê³„ ì¶”ì • (ì™„ì „ ìˆ˜ì • ë²„ì „)
Ortec Finance ë°©ë²•ë¡  ì°¸ê³ 

ì£¼ìš” ìˆ˜ì •ì‚¬í•­:
1. ë°ì´í„° ê¸¸ì´ë¥¼ 10ë…„ìœ¼ë¡œ ì¦ê°€ (ë‚˜ì´í€´ìŠ¤íŠ¸ ì •ë¦¬ ì¶©ì¡±)
2. ì£¼íŒŒìˆ˜ ëŒ€ì—­ì„ ë°ì´í„° ê¸¸ì´ì— ë§ê²Œ ì¬ì •ì˜
3. ìˆœìˆ˜ ëœë¤ ë°ì´í„°ë¡œ ì˜ˆì‹œ ë³€ê²½
"""

import numpy as np
import pandas as pd
from scipy import signal
from scipy.fft import fft, fftfreq, ifft
import matplotlib.pyplot as plt
from typing import Tuple, Dict, List
import platform

# í•œê¸€ í°íŠ¸ ì„¤ì •
def setup_korean_font():
    """ìš´ì˜ì²´ì œì— ë§ëŠ” í•œê¸€ í°íŠ¸ ì„¤ì •"""
    system = platform.system()
    
    if system == 'Windows':
        plt.rcParams['font.family'] = 'Malgun Gothic'
    elif system == 'Darwin':  # macOS
        plt.rcParams['font.family'] = 'AppleGothic'
    else:  # Linux
        try:
            plt.rcParams['font.family'] = 'NanumGothic'
        except:
            pass
    
    plt.rcParams['axes.unicode_minus'] = False

setup_korean_font()


class FrequencyDomainAnalyzer:
    """
    Frequency Domainì„ í™œìš©í•œ ìì‚° ë¶„ì„ í´ë˜ìŠ¤
    Ortec Financeì˜ Zero-Phase Filter ë°©ë²•ë¡  ê¸°ë°˜ (ì™„ì „ ìˆ˜ì • ë²„ì „)
    """
    
    def __init__(self, sampling_frequency: str = 'D'):
        """
        Parameters:
        -----------
        sampling_frequency : str
            ë°ì´í„° ë¹ˆë„ ('D': ì¼ë³„, 'W': ì£¼ë³„, 'M': ì›”ë³„)
        """
        self.sampling_freq = sampling_frequency
        
        # ì£¼íŒŒìˆ˜ ëŒ€ì—­ ì •ì˜ (ì •ê·œí™”ëœ ì£¼íŒŒìˆ˜: 0~0.5)
        # ì¼ë³„ ë°ì´í„° ê¸°ì¤€ (Nyquist = 0.5)
        if sampling_frequency == 'D':
            self.freq_bands = {
                'short_term': (0.04, 0.5),      # 2~25ì¼ ì£¼ê¸° (ë‹¨ê¸° ë…¸ì´ì¦ˆ)
                'medium_term': (0.008, 0.04),   # 25~125ì¼ (ê³„ì ˆì„±, ~1~6ê°œì›”)
                'business_cycle': (0.002, 0.008), # 125~500ì¼ (ê²½ê¸°ìˆœí™˜, ~0.5~2ë…„)
                'long_term': (0, 0.002)         # 500ì¼+ (ì¥ê¸° ì¶”ì„¸, 2ë…„+)
            }
        elif sampling_frequency == 'M':
            self.freq_bands = {
                'short_term': (1/3, 0.5),           # 2~3ê°œì›”
                'medium_term': (1/12, 1/3),         # 3ê°œì›”~1ë…„
                'business_cycle': (1/60, 1/12),     # 1ë…„~5ë…„
                'long_term': (0, 1/60)              # 5ë…„ ì´ìƒ
            }
    
    def zero_phase_filter(self, data: np.ndarray, 
                         low_freq: float = None,
                         high_freq: float = None,
                         order: int = 3) -> np.ndarray:
        """
        Zero-Phase Shift Filter ì ìš© (Band-pass, Low-pass, High-pass ì§€ì›)
        
        Parameters:
        -----------
        data : np.ndarray
            ì…ë ¥ ì‹œê³„ì—´ ë°ì´í„°
        low_freq : float or None
            í•˜í•œ ì£¼íŒŒìˆ˜ (Noneì´ë©´ low-pass)
        high_freq : float or None
            ìƒí•œ ì£¼íŒŒìˆ˜ (Noneì´ë©´ high-pass)
        order : int
            í•„í„° ì°¨ìˆ˜ (ë‚®ì¶¤ - ë„ˆë¬´ ë†’ìœ¼ë©´ ë¶ˆì•ˆì •)
            
        Returns:
        --------
        filtered_data : np.ndarray
            í•„í„°ë§ëœ ë°ì´í„°
        """
        nyquist = 0.5  # ì •ê·œí™”ëœ Nyquist ì£¼íŒŒìˆ˜
        
        # í•„í„° íƒ€ì… ê²°ì •
        if low_freq is None and high_freq is None:
            return data.copy()
        
        try:
            # Low-pass filter
            if low_freq is None:
                high_normalized = high_freq / nyquist
                high_normalized = min(max(high_normalized, 0.001), 0.95)
                
                b, a = signal.butter(order, high_normalized, btype='low')
            
            # High-pass filter
            elif high_freq is None:
                low_normalized = low_freq / nyquist
                low_normalized = min(max(low_normalized, 0.001), 0.95)
                
                b, a = signal.butter(order, low_normalized, btype='high')
            
            # Band-pass filter
            else:
                low_normalized = low_freq / nyquist
                high_normalized = high_freq / nyquist
                
                low_normalized = min(max(low_normalized, 0.001), 0.95)
                high_normalized = min(max(high_normalized, 0.001), 0.95)
                
                if low_normalized >= high_normalized:
                    return np.zeros_like(data)
                
                b, a = signal.butter(order, [low_normalized, high_normalized], btype='band')
            
            # Zero-phase filtering (ì–‘ë°©í–¥ í•„í„°ë§)
            filtered_data = signal.filtfilt(b, a, data)
            
            return filtered_data
            
        except Exception as e:
            # í•„í„°ë§ ì‹¤íŒ¨ ì‹œ 0 ë°˜í™˜
            print(f"Warning: Filter failed with low={low_freq}, high={high_freq}: {e}")
            return np.zeros_like(data)
    
    def decompose_frequency_bands(self, returns: pd.Series) -> Dict[str, np.ndarray]:
        """
        ìˆ˜ìµë¥ ì„ ì£¼íŒŒìˆ˜ ëŒ€ì—­ë³„ë¡œ ë¶„í•´
        
        Parameters:
        -----------
        returns : pd.Series
            ìì‚° ìˆ˜ìµë¥  ì‹œê³„ì—´
            
        Returns:
        --------
        decomposed : Dict[str, np.ndarray]
            ì£¼íŒŒìˆ˜ ëŒ€ì—­ë³„ ë¶„í•´ëœ ìˆ˜ìµë¥ 
        """
        data = returns.values
        decomposed = {}
        
        for band_name, freq_range in self.freq_bands.items():
            if band_name == 'long_term':
                # Long-term: low-pass filter
                filtered = self.zero_phase_filter(data, low_freq=None, 
                                                 high_freq=freq_range[1])
            else:
                # ë‚˜ë¨¸ì§€: band-pass filter
                low_freq, high_freq = freq_range
                filtered = self.zero_phase_filter(data, low_freq=low_freq, 
                                                 high_freq=high_freq)
            
            decomposed[band_name] = filtered
            
        return decomposed
    
    def calculate_expected_return(self, returns: pd.Series, 
                                 annualize: bool = True) -> Dict[str, float]:
        """
        ì£¼íŒŒìˆ˜ ëŒ€ì—­ë³„ ë° ì „ì²´ ê¸°ëŒ€ìˆ˜ìµë¥  ê³„ì‚°
        
        Parameters:
        -----------
        returns : pd.Series
            ìì‚° ìˆ˜ìµë¥  ì‹œê³„ì—´
        annualize : bool
            ì—°ìœ¨í™” ì—¬ë¶€
            
        Returns:
        --------
        expected_returns : Dict[str, float]
            ì „ì²´ ê¸°ëŒ€ìˆ˜ìµë¥ 
        """
        # ì „ì²´ ê¸°ëŒ€ìˆ˜ìµë¥ 
        total_mean = np.mean(returns)
        if annualize and self.sampling_freq == 'D':
            total_mean *= 252
        elif annualize and self.sampling_freq == 'M':
            total_mean *= 12
        
        expected_returns = {'total': total_mean}
        
        return expected_returns
    
    def calculate_volatility_spectral(self, returns: pd.Series, 
                                     annualize: bool = True) -> Dict[str, float]:
        """
        Power Spectral Densityë¥¼ ì´ìš©í•œ ì£¼íŒŒìˆ˜ë³„ ë³€ë™ì„± ê³„ì‚°
        
        Parameters:
        -----------
        returns : pd.Series
            ìì‚° ìˆ˜ìµë¥  ì‹œê³„ì—´
        annualize : bool
            ì—°ìœ¨í™” ì—¬ë¶€
            
        Returns:
        --------
        volatilities : Dict[str, float]
            ì£¼íŒŒìˆ˜ ëŒ€ì—­ë³„ ë° ì „ì²´ ë³€ë™ì„±
        """
        data = returns.values
        
        # Power Spectral Density ê³„ì‚°
        freqs, psd = signal.periodogram(data, scaling='density')
        
        volatilities = {}
        
        # ì£¼íŒŒìˆ˜ ëŒ€ì—­ë³„ ë³€ë™ì„± (PSD ì ë¶„)
        for band_name, freq_range in self.freq_bands.items():
            if band_name == 'long_term':
                # Long-term: 0ë¶€í„° ìƒí•œê¹Œì§€
                mask = (freqs >= 0) & (freqs <= freq_range[1])
            else:
                # ë‚˜ë¨¸ì§€: í•˜í•œë¶€í„° ìƒí•œê¹Œì§€
                low_freq, high_freq = freq_range
                mask = (freqs >= low_freq) & (freqs <= high_freq)
            
            # í•´ë‹¹ ëŒ€ì—­ì˜ ë¶„ì‚° (PSD ì ë¶„)
            if np.any(mask):
                # NumPy ë²„ì „ í˜¸í™˜ì„±: trapz ì‚¬ìš© (trapezoidëŠ” NumPy 1.22+ì—ì„œë§Œ ì‚¬ìš© ê°€ëŠ¥)
                try:
                    variance = np.trapz(psd[mask], freqs[mask])
                except AttributeError:
                    variance = np.trapezoid(psd[mask], freqs[mask])
                std_dev = np.sqrt(abs(variance))
            else:
                std_dev = 0.0
            
            if annualize and self.sampling_freq == 'D':
                std_dev *= np.sqrt(252)
            elif annualize and self.sampling_freq == 'M':
                std_dev *= np.sqrt(12)
                
            volatilities[band_name] = std_dev
        
        # ì „ì²´ ë³€ë™ì„± (ì‹œê°„ ì˜ì—­)
        total_vol = np.std(data)
        if annualize and self.sampling_freq == 'D':
            total_vol *= np.sqrt(252)
        elif annualize and self.sampling_freq == 'M':
            total_vol *= np.sqrt(12)
        volatilities['total'] = total_vol
        
        return volatilities
    
    def calculate_correlation_spectral(self, returns1: pd.Series,
                                      returns2: pd.Series) -> Dict[str, float]:
        """
        ì£¼íŒŒìˆ˜ ëŒ€ì—­ë³„ ìƒê´€ê³„ìˆ˜ ê³„ì‚°
        ê° ì£¼íŒŒìˆ˜ ëŒ€ì—­ìœ¼ë¡œ í•„í„°ë§ëœ ì‹ í˜¸ ê°„ì˜ ìƒê´€ê³„ìˆ˜ë¥¼ ì§ì ‘ ê³„ì‚°

        ì£¼ì˜: ë‚®ì€ ì£¼íŒŒìˆ˜ ëŒ€ì—­(ì¥ê¸°)ì€ ìœ íš¨ ìƒ˜í”Œ ìˆ˜ê°€ ì ì–´ ì‹ ë¢°ë„ê°€ ë‚®ì„ ìˆ˜ ìˆìŒ

        Parameters:
        -----------
        returns1, returns2 : pd.Series
            ë‘ ìì‚°ì˜ ìˆ˜ìµë¥  ì‹œê³„ì—´

        Returns:
        --------
        correlations : Dict[str, float]
            ì£¼íŒŒìˆ˜ ëŒ€ì—­ë³„ ë° ì „ì²´ ìƒê´€ê³„ìˆ˜
        """
        correlations = {}

        # ì£¼íŒŒìˆ˜ ëŒ€ì—­ë³„ë¡œ í•„í„°ë§ í›„ ìƒê´€ê³„ìˆ˜ ê³„ì‚°
        decomposed1 = self.decompose_frequency_bands(returns1)
        decomposed2 = self.decompose_frequency_bands(returns2)

        for band_name in self.freq_bands.keys():
            filtered1 = decomposed1[band_name]
            filtered2 = decomposed2[band_name]

            # í•„í„°ë§ëœ ì‹ í˜¸ ê°„ ìƒê´€ê³„ìˆ˜
            std1 = np.std(filtered1)
            std2 = np.std(filtered2)

            if std1 > 1e-10 and std2 > 1e-10:
                correlation = np.corrcoef(filtered1, filtered2)[0, 1]
                # NaN ì²´í¬
                if np.isnan(correlation):
                    correlation = 0.0

                # ìœ íš¨ ììœ ë„ ì¶”ì • (ë‚®ì€ ì£¼íŒŒìˆ˜ì¼ìˆ˜ë¡ ììœ ë„ ê°ì†Œ)
                # ì¥ê¸°/ê²½ê¸°ìˆœí™˜ ëŒ€ì—­ì€ ì‹ ë¢°ë„ê°€ ë‚®ìœ¼ë¯€ë¡œ ì°¸ê³ ìš©ìœ¼ë¡œë§Œ ì‚¬ìš©
                correlations[band_name] = correlation
            else:
                correlations[band_name] = 0.0

        # ì „ì²´ ìƒê´€ê³„ìˆ˜ (ì‹œê°„ ì˜ì—­)
        total_corr = np.corrcoef(returns1.values, returns2.values)[0, 1]
        correlations['total'] = total_corr

        return correlations
    
    def rolling_analysis(self, returns: pd.DataFrame, 
                        window: int = 252,
                        step: int = 63) -> pd.DataFrame:
        """
        Rolling windowë¡œ ì‹œê°„ì— ë”°ë¥¸ í†µê³„ ë³€í™” ì¶”ì 
        
        Parameters:
        -----------
        returns : pd.DataFrame
            ìì‚°ë“¤ì˜ ìˆ˜ìµë¥  (columns: ìì‚°ëª…)
        window : int
            ìœˆë„ìš° í¬ê¸°
        step : int
            ì´ë™ ê°„ê²©
            
        Returns:
        --------
        results : pd.DataFrame
            ì‹œê°„ì— ë”°ë¥¸ í†µê³„ëŸ‰ ë³€í™”
        """
        results = []
        
        for start in range(0, len(returns) - window, step):
            end = start + window
            window_data = returns.iloc[start:end]
            
            result_row = {'date': returns.index[end-1]}
            
            # ê° ìì‚°ì˜ í†µê³„
            for asset in returns.columns:
                vol = self.calculate_volatility_spectral(window_data[asset])
                result_row[f'{asset}_vol'] = vol['total']
            
            results.append(result_row)
        
        return pd.DataFrame(results)
    
    def generate_summary_report(self, returns: pd.DataFrame) -> pd.DataFrame:
        """
        ì „ì²´ ìì‚°êµ°ì— ëŒ€í•œ ìš”ì•½ ë¦¬í¬íŠ¸ ìƒì„±
        
        Parameters:
        -----------
        returns : pd.DataFrame
            ìì‚°ë“¤ì˜ ìˆ˜ìµë¥  (columns: ìì‚°ëª…)
            
        Returns:
        --------
        summary : pd.DataFrame
            ìì‚°ë³„ ê¸°ëŒ€ìˆ˜ìµë¥ , ë³€ë™ì„±, ìƒê´€ê³„ìˆ˜ ìš”ì•½
        """
        assets = returns.columns
        n_assets = len(assets)
        
        # ê¸°ëŒ€ìˆ˜ìµë¥ ê³¼ ë³€ë™ì„±
        summary_data = []
        for asset in assets:
            exp_ret = self.calculate_expected_return(returns[asset])
            vol = self.calculate_volatility_spectral(returns[asset])
            
            summary_data.append({
                'Asset': asset,
                'Expected_Return': exp_ret['total'],
                'Volatility': vol['total'],
                'Sharpe_Ratio': exp_ret['total'] / vol['total'] if vol['total'] > 0 else 0,
                'Short_Term_Vol': vol['short_term'],
                'Medium_Term_Vol': vol['medium_term'],
                'Business_Cycle_Vol': vol['business_cycle'],
                'Long_Term_Vol': vol['long_term']
            })
        
        summary_df = pd.DataFrame(summary_data)
        
        # ìƒê´€ê³„ìˆ˜ í–‰ë ¬
        corr_matrix = pd.DataFrame(index=assets, columns=assets)
        
        for i, asset1 in enumerate(assets):
            for j, asset2 in enumerate(assets):
                if i == j:
                    corr_matrix.loc[asset1, asset2] = 1.0
                elif i < j:
                    corr = self.calculate_correlation_spectral(
                        returns[asset1], returns[asset2]
                    )
                    corr_matrix.loc[asset1, asset2] = corr['total']
                    corr_matrix.loc[asset2, asset1] = corr['total']
        
        return summary_df, corr_matrix.astype(float)

    def stl_decomposition(self, returns: pd.Series, period: int = 21) -> Dict[str, pd.Series]:
        """
        STL (Seasonal and Trend decomposition using Loess) ë¶„í•´

        Parameters:
        -----------
        returns : pd.Series
            ìì‚° ìˆ˜ìµë¥  ì‹œê³„ì—´
        period : int
            ê³„ì ˆì„± ì£¼ê¸° (ì¼ë³„ ë°ì´í„°: 21 = ì›”ë³„, 63 = ë¶„ê¸°ë³„)

        Returns:
        --------
        decomposed : Dict[str, pd.Series]
            'original', 'trend', 'seasonal', 'residual' ì‹œê³„ì—´
        """
        try:
            from statsmodels.tsa.seasonal import STL

            # STL ë¶„í•´ ìˆ˜í–‰
            stl = STL(returns, period=period, seasonal=13)
            result = stl.fit()

            return {
                'original': returns,
                'trend': result.trend,
                'seasonal': result.seasonal,
                'residual': result.resid
            }
        except Exception as e:
            print(f"STL decomposition failed: {e}")
            # Fallback: ë‹¨ìˆœ ì´ë™í‰ê· ì„ trendë¡œ ì‚¬ìš©
            trend = returns.rolling(window=period, center=True).mean()
            residual = returns - trend
            seasonal = pd.Series(0, index=returns.index)

            return {
                'original': returns,
                'trend': trend.fillna(0),
                'seasonal': seasonal,
                'residual': residual.fillna(0)
            }

    def generate_stl_summary(self, returns: pd.DataFrame, period: int = None) -> pd.DataFrame:
        """
        ì „ì²´ ìì‚°ì— ëŒ€í•œ STL ë¶„í•´ ìš”ì•½ ìƒì„±

        Parameters:
        -----------
        returns : pd.DataFrame
            ìì‚°ë“¤ì˜ ìˆ˜ìµë¥ 
        period : int, optional
            ê³„ì ˆì„± ì£¼ê¸° (Noneì´ë©´ sampling_frequencyì— ë”°ë¼ ìë™ ì„¤ì •)
            ì¼ë³„: 21 (ì›”ë³„ íŒ¨í„´), ì›”ë³„: 12 (ì—°ë³„ íŒ¨í„´)

        Returns:
        --------
        summary : pd.DataFrame
            ìì‚°ë³„ STL ë¶„í•´ í†µê³„ëŸ‰
        """
        # ì£¼ê¸° ìë™ ì„¤ì •
        if period is None:
            if self.sampling_freq == 'D':
                period = 21  # ì¼ë³„ ë°ì´í„°: ì›”ë³„ íŒ¨í„´ (21 ê±°ë˜ì¼)
            elif self.sampling_freq == 'M':
                period = 12  # ì›”ë³„ ë°ì´í„°: ì—°ë³„ íŒ¨í„´ (12ê°œì›”)
            else:
                period = 12  # ê¸°ë³¸ê°’

        stl_summary = []

        for asset in returns.columns:
            stl_result = self.stl_decomposition(returns[asset], period=period)

            trend_vol = np.std(stl_result['trend'].dropna())
            seasonal_vol = np.std(stl_result['seasonal'])
            residual_vol = np.std(stl_result['residual'].dropna())
            total_vol = np.std(returns[asset])

            # ì—°ìœ¨í™”
            if self.sampling_freq == 'D':
                trend_vol *= np.sqrt(252)
                seasonal_vol *= np.sqrt(252)
                residual_vol *= np.sqrt(252)
                total_vol *= np.sqrt(252)
            elif self.sampling_freq == 'M':
                trend_vol *= np.sqrt(12)
                seasonal_vol *= np.sqrt(12)
                residual_vol *= np.sqrt(12)
                total_vol *= np.sqrt(12)

            # ê³„ì ˆì„± ê°•ë„ ê³„ì‚° (ë² ì´ìŠ¤ë¼ì¸ ëŒ€ë¹„ ìƒëŒ€ì  ê³„ì ˆì„±)
            # STLì˜ ë² ì´ìŠ¤ë¼ì¸: ìˆœìˆ˜ ëœë¤ ë°ì´í„°ì—ì„œ ~35% seasonal ì¶”ì¶œ
            # ì‹¤ì œ ê³„ì ˆì„± = (seasonal_vol / total_vol - baseline) / (1 - baseline)
            # ì´ë¥¼ 0~1 ë²”ìœ„ë¡œ ì •ê·œí™”
            raw_strength = seasonal_vol / total_vol if total_vol > 0 else 0
            baseline = 0.35  # STLì˜ ëœë¤ ë°ì´í„° ë² ì´ìŠ¤ë¼ì¸

            # ë² ì´ìŠ¤ë¼ì¸ ë³´ì • (0 ë¯¸ë§Œì€ 0ìœ¼ë¡œ, 1 ì´ˆê³¼ëŠ” 1ë¡œ í´ë¦¬í•‘)
            if raw_strength < baseline:
                seasonal_strength = 0.0
            else:
                # ë² ì´ìŠ¤ë¼ì¸ì„ ë¹¼ê³  ì¬ì •ê·œí™”
                seasonal_strength = min((raw_strength - baseline) / (1.0 - baseline), 1.0)

            stl_summary.append({
                'Asset': asset,
                'Trend_Vol': trend_vol,
                'Seasonal_Vol': seasonal_vol,
                'Residual_Vol': residual_vol,
                'Seasonal_Strength': seasonal_strength
            })

        return pd.DataFrame(stl_summary)


# ì‚¬ìš© ì˜ˆì‹œ
def example_usage():
    """
    ì‚¬ìš© ì˜ˆì‹œ - ìˆœìˆ˜ ëœë¤ ë°ì´í„° (10ë…„)
    """
    # 1. ìƒ˜í”Œ ë°ì´í„° ìƒì„± (3ê°œ ìì‚°, 10ë…„ì¹˜ ì¼ë³„ ë°ì´í„°)
    np.random.seed(42)
    n_days = 252 * 10  # 10ë…„ìœ¼ë¡œ ì¦ê°€
    dates = pd.date_range('2014-01-01', periods=n_days, freq='D')
    
    # ìˆœìˆ˜ ëœë¤ ìˆ˜ìµë¥  ì‹œë®¬ë ˆì´ì…˜
    returns_data = {
        'ì£¼ì‹': np.random.normal(0.0005, 0.015, n_days),    # ì—° 12.6%, ë³€ë™ì„± 23.7%
        'ì±„ê¶Œ': np.random.normal(0.0002, 0.005, n_days),    # ì—° 5.0%, ë³€ë™ì„± 7.9%
        'ì›ìì¬': np.random.normal(0.0003, 0.020, n_days)   # ì—° 7.6%, ë³€ë™ì„± 31.7%
    }
    
    returns_df = pd.DataFrame(returns_data, index=dates)
    
    # 2. Frequency Domain Analyzer ì´ˆê¸°í™”
    analyzer = FrequencyDomainAnalyzer(sampling_frequency='D')
    
    # 3. ìš”ì•½ ë¦¬í¬íŠ¸ ìƒì„±
    print("="*90)
    print("ìì‚°êµ°ë³„ Frequency Domain ë¶„ì„ ê²°ê³¼ (ì™„ì „ ìˆ˜ì • ë²„ì „ - 10ë…„ ë°ì´í„°)")
    print("="*90)
    
    summary, corr_matrix = analyzer.generate_summary_report(returns_df)
    
    print("\n[1] ìì‚°ë³„ ê¸°ëŒ€ìˆ˜ìµë¥  ë° ë³€ë™ì„±")
    print("-"*90)
    print(summary.to_string(index=False))
    
    print("\n[2] ìì‚° ê°„ ìƒê´€ê³„ìˆ˜ í–‰ë ¬")
    print("-"*90)
    print(corr_matrix)
    
    # 4. ê°œë³„ ìì‚° ìƒì„¸ ë¶„ì„
    print("\n[3] ì£¼ì‹ ìƒì„¸ ë¶„ì„")
    print("-"*90)
    
    exp_ret = analyzer.calculate_expected_return(returns_df['ì£¼ì‹'])
    print(f"\nì „ì²´ ê¸°ëŒ€ìˆ˜ìµë¥  (ì—°ìœ¨í™”): {exp_ret['total']*100:6.2f}%")
    
    vol = analyzer.calculate_volatility_spectral(returns_df['ì£¼ì‹'])
    print("\në³€ë™ì„± ë¶„ì„ (ì—°ìœ¨í™”):")
    print(f"  ì „ì²´ ë³€ë™ì„±        : {vol['total']*100:6.2f}%")
    print(f"  ë‹¨ê¸° ë³€ë™ì„±        : {vol['short_term']*100:6.2f}% ({vol['short_term']/vol['total']*100:.1f}%)")
    print(f"  ì¤‘ê¸° ë³€ë™ì„±        : {vol['medium_term']*100:6.2f}% ({vol['medium_term']/vol['total']*100:.1f}%)")
    print(f"  ê²½ê¸°ìˆœí™˜ ë³€ë™ì„±    : {vol['business_cycle']*100:6.2f}% ({vol['business_cycle']/vol['total']*100:.1f}%)")
    print(f"  ì¥ê¸°ì¶”ì„¸ ë³€ë™ì„±    : {vol['long_term']*100:6.2f}% ({vol['long_term']/vol['total']*100:.1f}%)")
    
    # 5. ìì‚° ê°„ ì£¼íŒŒìˆ˜ë³„ ìƒê´€ê´€ê³„
    print("\n[4] ì£¼ì‹-ì±„ê¶Œ ì£¼íŒŒìˆ˜ë³„ ìƒê´€ê³„ìˆ˜")
    print("-"*90)
    
    corr = analyzer.calculate_correlation_spectral(
        returns_df['ì£¼ì‹'], returns_df['ì±„ê¶Œ']
    )
    for band, value in corr.items():
        if band == 'total':
            band_display = 'Total (ì „ì²´)'
        else:
            band_display = band.replace('_', ' ').title()
        print(f"  {band_display:25s}: {value:7.4f}")
    
    print("\n" + "="*90)
    print("ğŸ’¡ í•´ì„ ê°€ì´ë“œ:")
    print("- Short Term      : ë‹¨ê¸°(5ì¼~3ê°œì›”) ë³€ë™")
    print("- Medium Term     : ì¤‘ê¸°(3ê°œì›”~1ë…„) ê³„ì ˆì„±")
    print("- Business Cycle  : ê²½ê¸°ìˆœí™˜(1~5ë…„)")  
    print("- Long Term       : ì¥ê¸° ì¶”ì„¸(5ë…„+)")
    print("- Total           : ì „ì²´ ê¸°ê°„ í‰ê· ")
    print("\nâœ… ì£¼ìš” ìˆ˜ì •ì‚¬í•­:")
    print("1. ë°ì´í„° ê¸¸ì´ë¥¼ 10ë…„ìœ¼ë¡œ ì¦ê°€ (ë‚˜ì´í€´ìŠ¤íŠ¸ ì •ë¦¬ ì¶©ì¡±)")
    print("2. ì£¼íŒŒìˆ˜ ëŒ€ì—­ì„ ì¸¡ì • ê°€ëŠ¥í•œ ë²”ìœ„ë¡œ ì¬ì •ì˜")
    print("3. í•„í„° ì°¨ìˆ˜ë¥¼ 3ìœ¼ë¡œ ë‚®ì¶¤ (ì•ˆì •ì„± ê°œì„ )")
    print("4. Medium Term ëŒ€ì—­ ì¶”ê°€ (4ê°œ ëŒ€ì—­ ë¶„ì„)")
    print("5. ìˆœìˆ˜ ëœë¤ ë°ì´í„° (ìƒê´€ê³„ìˆ˜ ~0 ì˜ˆìƒ)")
    print("\në¶„ì„ ì™„ë£Œ! âœ…")
    print("="*90)
    
    return analyzer, returns_df, summary, corr_matrix


if __name__ == "__main__":
    analyzer, returns_df, summary, corr_matrix = example_usage()